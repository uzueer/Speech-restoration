# ğŸ§  Speech Intelligibility Restoration using Deep Complex Convolutional Recurrent Network (DCCRN)

### ğŸ¯ Overview

This project focuses on **restoring intelligibility and quality of speech** for **hearing aid users** in noisy environments using **deep learning-based speech enhancement**.
We use the **Deep Complex Convolutional Recurrent Network (DCCRN)** architecture to perform **end-to-end speech denoising** on the **Valentini dataset** at 48 kHz.

The model learns to map **noisy speech** to **clean speech** in the complex spectrogram domain â€” effectively preserving both **magnitude and phase** information, which are crucial for perceptual speech quality.

---

## ğŸ§© Project Structure

```
dccrn_project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ valentina/
â”‚       â”œâ”€â”€ clean/
â”‚       â”‚   â”œâ”€â”€ train/
â”‚       â”‚   â”œâ”€â”€ val/
â”‚       â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ noisy/
â”‚           â”œâ”€â”€ train/
â”‚           â”œâ”€â”€ val/
â”‚           â””â”€â”€ test/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ dccrn_model.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ denoised_audio/
â”‚   â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ comparisons/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 1_model.py         # Model initialization
â”‚   â”œâ”€â”€ 2_dataset.py       # Dataset loader and preprocessing
â”‚   â”œâ”€â”€ 3_train.py         # Training script
â”‚   â”œâ”€â”€ 4_denoise.py       # Inference and denoising
â”‚   â””â”€â”€ 5_compare.py       # Metric evaluation (SNR, PESQ, STOI)
â”‚
â”œâ”€â”€ complexnn.py           # Custom complex-valued neural network layers
â”œâ”€â”€ conv_stft.py           # STFT/ISTFT operations
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/speech-restoration-dccrn.git
cd speech-restoration-dccrn
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # On Linux / macOS
venv\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Dataset Setup

Download the **Valentini Speech Dataset (48 kHz)** and structure it as follows:

```
data/valentina/clean/{train,val,test}
data/valentina/noisy/{train,val,test}
```

---

## ğŸ§  Model Architecture

The **DCCRN** combines:

* **Complex-valued Convolutional Layers** to extract spectral features
* **LSTM-based Recurrent Layers** for temporal modeling
* **Deconvolution Layers** for waveform reconstruction

Key modules:

* `ComplexConv2d` & `ComplexConvTranspose2d`
* `NavieComplexLSTM`
* `ComplexBatchNorm`

All implemented in **PyTorch** using custom complex-valued operations.

---

## ğŸš€ Training

To train the model:

```bash
python scripts/3_train.py
```

You can configure hyperparameters (epochs, batch size, learning rate) inside the script or via CLI arguments if implemented.

Model checkpoints will be saved under:

```
results/checkpoints/
```

---

## ğŸ§ Denoising / Inference

To denoise noisy speech samples:

```bash
python scripts/4_denoise.py --input data/valentina/noisy/test --output results/denoised_audio
```

Cleaned speech files will be stored in:

```
results/denoised_audio/
```

---

## ğŸ“Š Evaluation Metrics

After denoising, you can compare clean vs. denoised audio using:

```bash
python scripts/5_compare.py
```

The following metrics are calculated:

* **SNR (Signal-to-Noise Ratio)**
* **PESQ (Perceptual Evaluation of Speech Quality)**
* **STOI (Short-Time Objective Intelligibility)**

---

## ğŸ“ˆ Results

| Metric   | Noisy Input | Denoised Output (DCCRN) |
| :------- | :---------- | :---------------------- |
| SNR (dB) | ~3.2        | **14.8**                |
| PESQ     | 1.72        | **3.24**                |
| STOI     | 0.71        | **0.92**                |

> *(Values shown for illustration; your actual results may vary based on dataset and training parameters.)*

---

## ğŸ§¾ Research Paper (In Progress)

> **Title:** â€œRestoring Intelligibility of Speech for Hearing Aid Users in Noisy Environments using Deep Learningâ€
> **Institution:** SRM University, AP
> **Model Reference:** [DeepComplexCRN (Hu et al., Interspeech 2020)](https://github.com/huyanxin/DeepComplexCRN)

---

## ğŸ› ï¸ Tech Stack

| Component             | Technology                                           |
| --------------------- | ---------------------------------------------------- |
| Framework             | PyTorch                                              |
| Dataset               | Valentini Speech Dataset (48 kHz)                    |
| Model Type            | Deep Complex Convolutional Recurrent Network (DCCRN) |
| Audio Processing      | STFT / ISTFT                                         |
| Evaluation            | SNR, PESQ, STOI                                      |
| Deployment (optional) | Docker / Streamlit UI                                |

---


## ğŸ¤ Acknowledgements

Special thanks to:

* **huyanxin** for the [Deep Complex CRN architecture](https://github.com/huyanxin/DeepComplexCRN)
* **Valentini Speech Dataset** contributors
* **SRM University AP** for providing research infrastructure

---



## ğŸ“¬ Contact

**Author:** Syed Uzair
ğŸ“§ [[syeduzairsnu@gmail.com](mailto:syeduzairsnu@gmail.com)]
ğŸŒ [https://www.linkedin.com/in/syeduzairn/]

